{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Q-Table for Choosing Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from card_choice_gym import CardChoiceEnv\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LearnJoker(q_in=np.zeros((4, 9, 3, 4, 18, 4)), alpha_in=0.01, epsilon_in=0.5, gamma_in=0.95, episodes_in=100):\n",
    "  acts = ['STRG-BEAT', 'STRG-LOSS', 'WEAK-BEAT','WEAK-LOSS']\n",
    "  env = CardChoiceEnv()\n",
    "\n",
    "  alpha, gamma, epsilon = alpha_in, gamma_in, epsilon_in\n",
    "  q = q_in\n",
    "  \n",
    "  wins = []\n",
    "  good_calls = []\n",
    "\n",
    "  for i in range(episodes_in): \n",
    "    done = False\n",
    "    s = env.reset()\n",
    "    s0, s1, s2, s3, s4 = s\n",
    "    while True: \n",
    "      if np.random.random() < epsilon:\n",
    "      # choose random action\n",
    "        act_num = random.randint(0, 3)\n",
    "      else:\n",
    "        # greedy\n",
    "        act_num = np.argmax(q[s0, s1, s2, s3, s4])\n",
    "      \n",
    "      action = acts[act_num]\n",
    "\n",
    "      s_, r, done, _ = env.step(action)\n",
    "\n",
    "      s_0, s_1, s_2, s_3, s_4 = s_\n",
    "      td_target = r + gamma * np.argmax(q[s_0, s_1, s_2, s_3, s_4])\n",
    "      td_error = td_target - q[s0, s1, s2, s3, s4, act_num]\n",
    "      s = s_\n",
    "\n",
    "      q[s0, s1, s2, s3, s4, act_num] += alpha * td_error\n",
    "      if done:\n",
    "        if r > 0:\n",
    "          wins.append(i)\n",
    "          good_calls.append(env.call_state)\n",
    "        break\n",
    "  return wins, good_calls, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CardChoiceEnv' object has no attribute 'call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000003?line=0'>1</a>\u001b[0m eps \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000003?line=1'>2</a>\u001b[0m wins, _, q \u001b[39m=\u001b[39m LearnJoker(epsilon_in\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m, episodes_in\u001b[39m=\u001b[39;49meps)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mlen\u001b[39m(wins) \u001b[39m/\u001b[39m eps\n",
      "\u001b[1;32m/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb Cell 3'\u001b[0m in \u001b[0;36mLearnJoker\u001b[0;34m(q_in, alpha_in, epsilon_in, gamma_in, episodes_in)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000002?line=33'>34</a>\u001b[0m       \u001b[39mif\u001b[39;00m r \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000002?line=34'>35</a>\u001b[0m         wins\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000002?line=35'>36</a>\u001b[0m         good_calls\u001b[39m.\u001b[39mappend(env\u001b[39m.\u001b[39;49mcall, env\u001b[39m.\u001b[39mcall_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000002?line=36'>37</a>\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/konstantinekahadze/Desktop/Projects/JustNines/src/q-learning-card-choice.ipynb#ch0000002?line=37'>38</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wins, good_calls, q\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CardChoiceEnv' object has no attribute 'call'"
     ]
    }
   ],
   "source": [
    "eps = 1000\n",
    "wins, _, q = LearnJoker(epsilon_in=0.9, episodes_in=eps)\n",
    "len(wins) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1000\n",
    "wins, _, q = LearnJoker(q_in=q,epsilon_in=0, episodes_in=eps)\n",
    "len(wins) /eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_q_table(table):\n",
    "    file = '../models/q-table.npy'\n",
    "    with open(file, \"wb\"):\n",
    "        np.save(file, table, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_q_table(q)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2496e9c8954cfb85d8fd929854c5948b9695e07ca8c3f102449d1d34246a9882"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
